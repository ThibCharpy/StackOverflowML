[
  {
    "id":"49510225",
    "title":"Rotating image in python: extrapolate background color",
    "tags": "python image colors rotation python-imaging-library ",
    "text": "    I am rotating an image with the following python code:     This makes the following transformation:   to   As you can see, the background is black. This question asks how to fill the background with a specific color. However, I would like to fill the background with the color of the image. Because I need to rotate many images, I do not want to set the background to a fixed color.  Is there some way to extend the image at the edges, with a color extrapolated from the image? Ideally, this would also work if the image does not have a uniform background.     ",
    "code":" from PIL import Image  img = Image.open( banana.jpg ) rotated = img.rotate(10) rotated.save( banana-rotated.jpg ) "
  },
  {
    "id":"49510143",
    "title":"TensorFlow is returning an error when used in Laravel project, why?",
    "tags":"php python laravel shell tensorflow ",
    "text":"    I run this command from bash (in my case zsh)     And I am getting the correct output which is:     But when I try to reproduce the same thing in my laravel project I am getting an error. My code inside my controller is this one:     I am using Composer - Process class in order to execute the command which comes built-in with Laravel. After running this code I am getting this error:  The command \"python images/classify_image.py --image_file images/new_name.jpg\" failed. Exit Code: 1(General error) Working directory: /var/www/html/share/public Output: ================ Error Output: ================ Traceback (most recent call last): File \"images/classify_image.py\", line 46, in  import tensorflow as tf ImportError: No module named tensorflow  Someone can give me hints, why I am getting this error? It seems like Laravel have no access to TensorFlow, but why I am able to execute this command from shell not in Laravel project?     ",
    "code":" python images/classify_image.py --image_file images/new_name.jpg power drill (score = 0.97464) hand blower, blow dryer, blow drier, hair dryer, hair drier (score = 0.00101) carpenter s kit, tool kit (score = 0.00043) screwdriver (score = 0.00034) joystick (score = 0.00028)  $process = new Process( python images/classify_image.py --image_file images/new_name.jpg );  $process-&gt;run(); // executes after the command finishes if (!$process-&gt;isSuccessful()) {    throw new ProcessFailedException($process); } dd($process-&gt;getOutput()); "},
  {
    "id" : "49510078",
    "title": "When to use floc and fscale parameters in scipy?",
    "tags": "python scipy ",
    "text": "    Although I have read lots of posts about fitting  distributions in python, I am still confused about usage   and   parameters. For general information I mainly used this, this and this sources.  I know, that given distribution lets say f(x) becomes more general distribution when using   and   parameters, which can be described by formula f(x) = f((x-loc)/scale).  In scipy, we have to choice. When fitting a distribution, using formula  , the initial guess of   parameter is 0 and initial guess of   parameter is 1 (so that we assume that the parametrized distribution is close to nonparametrized distribution). We can also force scipy to fit  original  distribution f(x) using  .  My question is: is there any general advice when to force scipy to fit  original distribution  besides the  parametrized one ?  Here is the example:            As you can see, the   improved a lot the fit in lognorm case, in gamma case it didint change the fit at all.  Sorry for long demontration, here is my question again: Is there any general advice when to specify   and   and when to use custome   and  ?     ",
    "code": " floc fscale loc scale distr.fit(x) loc fscale distr.fit(x, floc = 0, fscale = 1) # generate some data from scipy.stats import lognorm, fisk, gamma from statsmodels.distributions.empirical_distribution import ECDF import numpy as np import matplotlib.pyplot as plt  x1 = [18. for i in range(36)] x2 = [19. for i in range(17)] x3 = [22. for i in range(44)] x4 = [27. for i in range(63)] x5 = [28.2 for i in range(8)] x6 = [32. for i in range(104)] x7 = [32.6 for i in range(29)] x8 = [33. for i in range(85)] x9 = [33.4 for i in range(27)] x10 = [34.2 for i in range(49)] x11 = [36. for i in range(99)] x12 = [36.2 for i in range(35)] x13 = [37. for i in range(98)] x14 = [38. for i in range(25)] x15 = [38.4 for i in range(39)] x16 = [39. for i in range(25)] x17 = [42. for i in range(54)]  # empirical distribution function xp = x1 + x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17 yp = ECDF(xp)   # fit lognormal distribution with parametrization pars1 = lognorm.fit(xp) # fit lognormal distribution with floc = 0 pars2 = lognorm.fit(xp, floc = 0) #plot the result X = np.linspace(min(xp), max(xp), 10000) plt.plot(yp.x, yp.y,  ro ) plt.plot(X, lognorm.cdf(X, pars1[0], pars1[1], pars1[2]),  b- ) plt.plot(X, lognorm.cdf(X, pars2[0], pars2[1], pars2[2]),  g- ) plt.show()  #fit the gamma distribution pars1 = gamma.fit(xp) pars2 = gamma.fit(xp, floc = 0) #plot the result X = np.linspace(min(xp), max(xp), 10000) plt.plot(yp.x, yp.y,  ro ) plt.plot(X, gamma.cdf(X, pars1[0], pars1[1], pars1[2]),  b- ) plt.plot(X, gamma.cdf(X, pars2[0], pars2[1], pars2[2]),  g- ) plt.show()        floc = 0 floc = 0 fscale = 1 loc = 0 scale = 1"},
  {
    "id" : "49510049",
    "title": "How to import Json file to MongoDB using Python",
    "tags": "python json mongodb ",
    "text": "    I have this Json file, currencies.json     }  And this connection in Python     My db name is countries_db with the currency collection. Is there a way to import the file to the db using python? Thanks for your help.     ",
    "code": " { \"AUD\": 1.5978, \"BGN\": 1.9558, \"BRL\": 4.0726, \"CAD\": 1.5868, \"CHF\": 1.1703, \"CNY\": 7.7975, \"CZK\": 25.405, \"DKK\": 7.4478, \"GBP\": 0.87285, \"HKD\": 9.6889, \"HRK\": 7.4398, \"HUF\": 312.9, \"IDR\": 16993.0, \"ILS\": 4.2984, \"INR\": 80.255, \"ISK\": 122.1, \"JPY\": 129.74, \"KRW\": 1330.3, \"MXN\": 22.88, \"MYR\": 4.8365, \"NOK\": 9.5715, \"NZD\": 1.7024, \"PHP\": 64.64, \"PLN\": 4.2262, \"RON\": 4.663, \"RUB\": 70.539, \"SEK\": 10.194, \"SGD\": 1.6216, \"THB\": 38.495, \"TRY\": 4.888, \"USD\": 1.2346, \"ZAR\": 14.52  from pymongo import MongoClient client = MongoClient ( localhost , 27017) db = client[ countries_db ] collection_currency = db[ currency ] "
  },
  {
    "id" : "49510042",
    "title": "continues rolling sum by multiply minutes of datetime in python", "tags": "python pandas ", "text": "    I have this df     I am looking for continues rolling sum which is depended on the minutes.  I need a continues rolling for the last 2 minutes. so every time I get the sum of X but when the datetime is increasing by 1 minute than it will drop the prior tailed 1 min so alway I will have only last 2 minutes. The problem is that there is no same amount of data per each minute.   I tried you use:      but it is resting the sum every 2 minutes and not doing continues rolling.  thanks for your help!     ",
    "code": "       dateTime                  1min        hour minute X   EXPECTED Rolling_X 2017-09-19  02:00:04    2017-09-19  02:00:00    2   0   5   5 2017-09-19  02:00:04    2017-09-19  02:00:00    2   0   1   6 2017-09-19  02:00:04    2017-09-19  02:00:00    2   0   1   7 2017-09-19  02:00:22    2017-09-19  02:00:00    2   0   2   9 2017-09-19  02:01:31    2017-09-19  02:01:00    2   1   0   9 2017-09-19  02:01:31    2017-09-19  02:01:00    2   1   1   10 2017-09-19  02:01:32    2017-09-19  02:01:00    2   1   1   11 2017-09-19  02:01:34    2017-09-19  02:01:00    2   1   6   17 2017-09-19  02:01:35    2017-09-19  02:01:00    2   1   5   22 2017-09-19  02:01:35    2017-09-19  02:01:00    2   1   0   22 2017-09-19  02:01:39    2017-09-19  02:01:00    2   1   1   23 2017-09-19  02:01:58    2017-09-19  02:01:00    2   1   2   25 2017-09-19  02:01:58    2017-09-19  02:01:00    2   1   0   25 2017-09-19  02:02:02    2017-09-19  02:02:00    2   2   3   19 2017-09-19  02:02:32    2017-09-19  02:02:00    2   2   0   19 2017-09-19  02:02:32    2017-09-19  02:02:00    2   2   1   20 2017-09-19  02:02:40    2017-09-19  02:02:00    2   2   15  35 2017-09-19  02:02:41    2017-09-19  02:02:00    2   2   6   41 2017-09-19  02:02:44    2017-09-19  02:02:00    2   2   1   42 2017-09-19  02:02:53    2017-09-19  02:02:00    2   2   3   45 2017-09-19  02:03:00    2017-09-19  02:03:00    2   3   1   30 2017-09-19  02:03:00    2017-09-19  02:03:00    2   3   1   31 2017-09-19  02:03:05    2017-09-19  02:03:00    2   3   1   32 2017-09-19  02:04:07    2017-09-19  02:04:00    2   4   7   10 2017-09-19  02:04:58    2017-09-19  02:04:00    2   4   2   12 2017-09-19  02:05:22    2017-09-19  02:05:00    2   5   11  23 2017-09-19  02:05:36    2017-09-19  02:05:00    2   5   2   25  s2m = df[ dateTime ].dt.floor( 2T ).diff().shift(-1).eq(pd.Timedelta( 2 minutes )) s2m1 = df[ X ].cumsum() df[ truncate_2m ] = s2m.mul(s2m1).diff().where(lambda x: x &lt; 0).ffill().add(s2m1, fill_value=0) "},
  {"id": "49510037",
    "title": "How to fetch data from an excel sheet and get the output in set format?",
    "tags": "python excel pandas ",
    "text": "    I m making a movie recommendation system. I need a python code which converts the data imported from an excel sheet to a set format (as shown below).  enter image description here  Code to import data from the excel sheet:     Output I get:     enter image description here  From here I need to have an output like this:     Code I am using (but showing error):        ",
    "code": " import pandas as pd from pandas import ExcelWriter from pandas import ExcelFile  df = pd.read_excel( project.xlsx , sheetname= Sheet1 ) df.head(40)          USER       MOVIE    RATINGS 0   Julia Roberts   Shrek   2.5 1   NaN         V for Vendetta  3.5 2   NaN         Pretty Woman    3.0 3   NaN            Star Wars    3.5 4   NaN    While You Were Sleeping  2.5 5   NaN     Phone Booth 3.0 6   Drew Barrymore  Shrek   3.0 7   NaN       V for Vendetta    3.5 8   NaN     Pretty Woman    1.5 9   NaN        Star Wars    5.0 10  NaN      Phone Booth    3.0 11  NaN   While You Were Sleeping   3.5 12  Kate Winslet       Shrek    2.5 13  NaN       V for Vendetta    3.0 14  NaN        Star Wars    3.5 15  NaN       Phone Booth   4.0 16  Tom Hanks   While You Were Sleeping 2.5 17  NaN           V for Vendetta    3.5 18  NaN         Pretty Woman    3.0 19  NaN         Star Wars   4.0 20  NaN     Phone Booth 4.5 .... ...... ...... ......  dataset={   Julia Roberts : {   Shrek : 2.5,   I am Legend :3.0,   V for Vendetta : 3.5,   Pretty Woman : 0,  \"My Sister s Keeper\":5.0,   Star Wars : 3.5,   Me Before You : 3.0,   While You Were Sleeping : 2.5,   Phone Booth : 3.0},    Drew Barrymore : { Shrek : 3.0,   V for Vendetta : 3.5,   Pretty Woman : 1.5,  \"My Sister s Keeper\":4.0,   Star Wars : 5.0,   Phone Booth : 3.0,   While You Were Sleeping : 3.5},     Tom Hanks : { V for Vendetta : 3.5,   Pretty Woman : 3.0,   Phone Booth : 4.5,   Star Wars : 4.0,   While You Were Sleeping : 2.5,   I am Legend :3.5},    Sandra Bullock : { Shrek : 3.0,   V for Vendetta : 4.0,   Pretty Woman : 2.0,   Star Wars : 3.0,   I am Legend :4.5,  \"My Sister s Keeper\":3.5,    Phone Booth : 3.0,   While You Were Sleeping : 2.0} }  max_nb_row = 0 for sheet in df.sheets():   max_nb_row = max(max_nb_row, sheet.nrows)  for row in range(max_nb_row) :   for sheet in df.sheets() :     if row &lt; sheet.nrows :       print (sheet.row(row)) "
  },
  {
    "id" : "49509950",
    "title": "Django ORM Query optimization, gettting large pool error on `__in` or union `|`",
    "tags": "python django database orm ",
    "text": "    Example code:     Now I have a one query set which has previeous data     When I excute below code     its throwing below error:     DatabaseError: ORA-04031: unable to allocate 4152 bytes of shared   memory (\"large pool\",\"unknown object\",\"session heap\",\"kxsFrame4kPage\")   if I modified      previous_queryset.values_list( field__name , flat=True)   to      list(previous_queryset.values_list( field__name , flat=True))   its working fine but it is taking too much time to get data from the database.  I need to improve the performance of above code but till now I did not find any solution.     ",
    "code": " choices = [[ a ,  b ,  c ,  d ],            [ a ,  c ,  d ,  e ],            [ a ,  d ,  e ,  f ],            [ a ,  f ,  j ,  k ],            ........more then 30 choices list......            ]  previous_queryset = Example.objects.filter(field__name__in=some_choices)  query_set = Example.objects.filter(field__name__in=some_choices) for ch in choices:    filter_set = some_function(ch)    example_query_set = query_set.filter(filter_set).exclude(field__name__in=                        previous_queryset.values_list( field__name , flat=True)))                         | previous_queryset     previous_queryset = example_query_set  "
  },
  {
    "id" : "49509946",
    "title": "Creating a graph with 3 sets of data within each dataset",
    "tags": "python pandas ",
    "text": "    I m working with a CSV file that contains data as followed, which I ve converted into a dataset. The code I have so far:      What I would like to do is convert this into a column graph, with each data set separated by year (2015, 2010, 2005, and 2000), but within those year groups, they have 3 columns of Both sex, Male, and Female. I m familiar with creating column graphs if the data set only has two sets of data within it (so if this had only both sex, and male, for example).  This is the code I ve attempted to use:     I obtain an error, \"Year\" when running the code, which is understandable. I ve left hue as \"country\", but will change once I figure out how to get this right.  Question: How can I create a column graph when each of my data sets contains three points of data? I have checked the Python API and I could not find a similar question.     ",
    "code": " import pandas as pd import matplotlib.pyplot as plt          import seaborn as sns     df = pd.read_csv( MH_12.csv )     df = df.set_index(\"Country\")      df2 = df.loc[\"Colombia\", \"2005\"]     print(df2.values)          Dataset2015 = {\"Both sex\":[ 7.1],                    \"Male\" :[10.9],                    \"Female\" :[ 3.1]}     Dataset2010 = {\"Both sex\":[ 7.0],                    \"Male\" :[11.1],                    \"Female\" :[ 2.8]}     Dataset2005 = {\"Both sex\":[ 7.3],                    \"Male\" :[11.7],                    \"Female\" :[ 2.6]}     Dataset2000 = {\"Both sex\":[ 6.7],                    \"Male\" :[10.9],                    \"Female\" :[ 2.3]}  df3 = pd.DataFrame(Dataset2015) df3[ year ] =  2015  df4 = pd.DataFrame(Dataset2010) df4[ year ] =  2010  df5 = pd.DataFrame(Dataset2005) df5[ year ] =  2005  df6 = pd.DataFrame(Dataset2000) df6[ year ] =  2000  df7 = pd.concat([df3,df4,df5,df6]) sns.factorplot(errcolor=\".2\", edgecolor=\".2\", data = df, hue= country , x= year , y= Mental Health Issues per 100,000 Population , kind= bar , ci=None, aspect=3, size=7); plt.title( Mental Health Issues in Colombia ) plt.xticks(rotation=45); plt.show() "
  },
  {
    "id" : "49509895",
    "title": "Python Stop a For-Loop at a special number?",
    "tags": "python list selenium for-loop web-scraping ",
    "text": "    I wanna stop my for-loop at a certain point. I know the method   but this doesn c2 b4t help me because I am iterating in a list. Either it doesnt Work with   or I just dont know.  Globally I save this Variable.     That is my method. Everything works fine. I must delete some Code hopefully you understand this.     Best regards  KaanDev     ",
    "code": " range() range() productAmount = 4  def amazonChecker(keyword):  driver = webdriver.Chrome( ./driver/chromedriver.exe ) driver.get(url)  titels = driver.find_elements_by_tag_name( h2 ) for titel in titels:     counter =+ 1     if counter &lt; productAmount:         print(titel.text)  sleep(5) driver.close "
  },
  {
    "id" : "49509871",
    "title": "Input dimension error in Keras",
    "tags": "python tensorflow keras ",
    "text": "    I know this error has been posted several times, but I didn t find any case that matched mine and I really don t understand why this error arises on that particular case.  So I m trying to finetune a VGG16 network, and as training didn t seem to work if I just changed the output layer and made some earlier layers trainable, I just want to try it by removing the last layers and add new ones back.  Specifically, I remove the top layers up to the last convolution layer, so the network looks like this :     Then I add a convolution layer:     and it raises the well-known error:     I really don t understand why ndim=2 is found for that new layer, it does not make sense to me, even doing      doesn t solve it. But I m still kind of new to Keras so there must be some subtlety I don t get yet. I m using Keras 2.1.5 with a Tensorflow backend.     ",
    "code": " Layer (type)                 Output Shape              Param #    ================================================================= input_1 (InputLayer)         (None, 224, 224, 3)       0          _________________________________________________________________ block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792       _________________________________________________________________ block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928      _________________________________________________________________ block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0          _________________________________________________________________ block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856      _________________________________________________________________ block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584     _________________________________________________________________ block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0          _________________________________________________________________ block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168     _________________________________________________________________ block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080     _________________________________________________________________ block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080     _________________________________________________________________ block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0          _________________________________________________________________ block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160    _________________________________________________________________ block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808    _________________________________________________________________ block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808    _________________________________________________________________ block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0          _________________________________________________________________ block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808    _________________________________________________________________ block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808    ================================================================= Total params: 12,354,880 Trainable params: 0 Non-trainable params: 12,354,880 _________________________________________________________________  vgg16_model_ft.add(Conv2D(512, (3,3), padding= same , activation= relu ))  ValueError: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=2  vgg16_model_ft.add(Conv2D(512, (3,3), padding= same , activation= relu , input_shape=vgg16_model_ft.layers[-1].output_shape)) "
  },
  {
    "id" : "49509860",
    "title": "Recursive Square Root Function Not Iterating",
    "tags": "python iteration ",
    "text": "    I am having trouble with iterating a function in Python.   I am trying to output values following:     This is the program:     For some reason, it only calculates output (a) for the input of x given. It will not print the values of      like I am trying to do.     ",
    "code": " def calculate(x):     if x == 1:       return 1.414     elif x &gt;= 2:           a = (calculate(x-1)**2 + (1/(calculate(x-1)**2)))**(0.5)           return (a)           calculate (x-1)  input 1,2,3,4 ... x"
  },
  {
    "id" : "49509790",
    "title": "TypeError when importing requests from python",
    "tags": "python python-requests typeerror ",
    "text": "    I m having problems using the requests library. I used pip to install it and I also intalled through github and the installation goes just fine. But when I try to import the lib, I get this error:     I saw in another post a person saying something about the PATH, but I didn t understand... Something related to a conflict between /usr/bin and /usr/local/bin. I don t know if this have something to do with it. I also have used pip2.7 to install the lib and it shows in the   command. I d appreciate any help.     ",
    "code": " Python 2.7.14+ (default, Mar 13 2018, 15:23:44)  [GCC 7.3.0] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import requests Traceback (most recent call last):   File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;   File \"/usr/local/lib/python2.7/dist-packages/requests/__init__.py\", line 95, in &lt;module&gt;     from urllib3.contrib import pyopenssl   File \"/usr/lib/python2.7/dist-packages/urllib3/contrib/pyopenssl.py\", line 46, in &lt;module&gt;     import OpenSSL.SSL   File \"/usr/lib/python2.7/dist-packages/OpenSSL/__init__.py\", line 8, in &lt;module&gt;     from OpenSSL import crypto, SSL   File \"/usr/lib/python2.7/dist-packages/OpenSSL/crypto.py\", line 12, in &lt;module&gt;     from cryptography import x509   File \"/usr/lib/python2.7/dist-packages/cryptography/x509/__init__.py\", line 8, in &lt;module&gt;     from cryptography.x509.base import (   File \"/usr/lib/python2.7/dist-packages/cryptography/x509/base.py\", line 16, in &lt;module&gt;     from cryptography.x509.extensions import Extension, ExtensionType   File \"/usr/lib/python2.7/dist-packages/cryptography/x509/extensions.py\", line 24, in &lt;module&gt;     from cryptography.x509.general_name import GeneralName, IPAddress, OtherName   File \"/usr/lib/python2.7/dist-packages/cryptography/x509/general_name.py\", line 18, in &lt;module&gt;     from cryptography.x509.name import Name   File \"/usr/lib/python2.7/dist-packages/cryptography/x509/name.py\", line 28, in &lt;module&gt;     _ASN1_TYPE_TO_ENUM = dict((i.value, i) for i in _ASN1Type) TypeError:  type  object is not iterable &gt;&gt;&gt;   pip list"
  }
]